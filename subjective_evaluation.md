To provide a robust and multi-faceted operationalization of user perception for RQ3, we adopted several established scales from HCI and psychology. This approach allowed us to move beyond simple detection rates and capture the nuanced, subjective quality of the interaction. All items were presented as 7-point Likert scales. 

- **Usability (UMUX-Lite)**: We used the UMUX-Lite scale to measure perceived usability. This scale captures both the system's ease of use and its ability to meet the user's needs. We selected it to test whether the manipulative strategies introduced any conversational friction or made the chatbot feel less effective at its primary task.

- **Trust (Trust Towards Automation Scale)**: We adapted the widely-used scale from Jian et al. to measure trust in the chatbot. This dimension was critical for evaluating the ``paradoxical'' finding: that an attack could not only be stealthy but could even increase user trust by appearing more empathetic or personalized.

- **Negative Opinions (NARS)**: We used sub-scales from the Negative Attitudes towards Robots Scale (NARS). This was chosen to detect any latent negative feelings (e.g., anxiety, discomfort) the user might have developed, even if they could not articulate why. A high NARS score would imply the attack's stealth was compromised.

- **Task Load (NASA-TLX)**: This was our most granular measure of interaction quality. We used the full NASA-Task Load Index (TLX) to assess the cognitive cost of the interaction. A stealthy attack should not require more cognitive resources than a benign interaction. The sub-dimensions are: 

  - **Mental Load**: How much mental and perceptual activity was required? (e.g., "Was the task easy or demanding?") 
  - **Physical Load**: How much physical activity was required? (Note: This may be expected to be low for a text-chat task, but included for scale completeness.)
  - **Temporal Load**: How much time pressure did the user feel? 
  - **Performance**: How successful did the user feel they were in accomplishing their task goals?
  - **Effort**: How hard did the user have to work (mentally and physically) to accomplish their level of performance?
  - **Frustration**: How insecure, discouraged, irritated, or annoyed did the user feel during the task? (This is a key indicator of interaction friction.)

- **Satisfaction**: Finally, we included a standard, single-item measure for overall satisfaction with the interaction, which serves as a holistic summary of the user's entire experience.
